{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: conda\n",
      "zsh:1: command not found: conda\n",
      "zsh:1: command not found: conda\n",
      "zsh:1: command not found: conda\n"
     ]
    }
   ],
   "source": [
    "# Update sklearn to prevent version mismatches\n",
    "!conda install scikit-learn\n",
    "!conda update scikit-learn\n",
    "!conda install joblib \n",
    "!conda update joblib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data_5hoods_datetime.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select columns of interst\n",
    "df = df[[\"Beat\",\n",
    "    \"Occur Time\",\n",
    "    \"Neighborhood\",\n",
    "    \"Location Type\",\n",
    "    \"Latitude\",\n",
    "    \"Longitude\",\n",
    "    \"Occur Year\",\n",
    "    \"Occur Month\",\n",
    "    \"Occur Day\",\n",
    "    \"Occur DayofWeek\",\n",
    "    \"UCR Literal\"]]\n",
    "#df.dropna(subset=['Location Type', 'Occur Time'])\n",
    "df.dropna(subset=['Beat'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer \n",
    "y = df[\"UCR Literal\"]\n",
    "X = df.drop(columns=[\"UCR Literal\"])\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder() \n",
    "X['Neighborhood']= le.fit_transform(X['Neighborhood']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n",
    "\n",
    "Use `UCR Literal` for the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For example, if variable y is a binary categorical variable with values 0 and 1 and there are 25% of zeros and 75% of ones, stratify=y will make sure that your random split has 25% of 0's and 75% of 1's.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_scaler = MinMaxScaler().fit(X_train)#Compute the minimum and maximum to be used for later scaling.\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)#Scale features of X_train according to feature_range.\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LARCENY-FROM VEHICLE', 'ROBBERY-PEDESTRIAN', 'BURGLARY-NONRES',\n",
       "       'AGG ASSAULT', 'LARCENY-NON VEHICLE', 'AUTO THEFT',\n",
       "       'BURGLARY-RESIDENCE', 'ROBBERY-COMMERCIAL', 'HOMICIDE',\n",
       "       'ROBBERY-RESIDENCE'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_train\n",
    "y_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beat</th>\n",
       "      <th>Occur Time</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Location Type</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Occur Year</th>\n",
       "      <th>Occur Month</th>\n",
       "      <th>Occur Day</th>\n",
       "      <th>Occur DayofWeek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36637</th>\n",
       "      <td>604.0</td>\n",
       "      <td>1630</td>\n",
       "      <td>4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>33.76142</td>\n",
       "      <td>-84.36492</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52369</th>\n",
       "      <td>505.0</td>\n",
       "      <td>1230</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>33.77448</td>\n",
       "      <td>-84.38263</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9562</th>\n",
       "      <td>505.0</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>33.77454</td>\n",
       "      <td>-84.37885</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21715</th>\n",
       "      <td>511.0</td>\n",
       "      <td>930</td>\n",
       "      <td>2</td>\n",
       "      <td>99.0</td>\n",
       "      <td>33.75281</td>\n",
       "      <td>-84.39197</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40637</th>\n",
       "      <td>604.0</td>\n",
       "      <td>2030</td>\n",
       "      <td>4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33.75772</td>\n",
       "      <td>-84.37067</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Beat  Occur Time  Neighborhood  Location Type  Latitude  Longitude  \\\n",
       "36637  604.0        1630             4           21.0  33.76142  -84.36492   \n",
       "52369  505.0        1230             3           13.0  33.77448  -84.38263   \n",
       "9562   505.0         200             3           13.0  33.77454  -84.37885   \n",
       "21715  511.0         930             2           99.0  33.75281  -84.39197   \n",
       "40637  604.0        2030             4           18.0  33.75772  -84.37067   \n",
       "\n",
       "       Occur Year  Occur Month  Occur Day  Occur DayofWeek  \n",
       "36637      2013.0         12.0       16.0              0.0  \n",
       "52369      2017.0          9.0        3.0              6.0  \n",
       "9562       2009.0          1.0        4.0              6.0  \n",
       "21715      2011.0          1.0       25.0              1.0  \n",
       "40637      2014.0         10.0       11.0              5.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using LabelEncoder and MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36637    LARCENY-FROM VEHICLE\n",
       "52369    LARCENY-FROM VEHICLE\n",
       "9562       ROBBERY-PEDESTRIAN\n",
       "21715         BURGLARY-NONRES\n",
       "40637      ROBBERY-PEDESTRIAN\n",
       "                 ...         \n",
       "54343              AUTO THEFT\n",
       "38158    LARCENY-FROM VEHICLE\n",
       "860       LARCENY-NON VEHICLE\n",
       "15795      ROBBERY-PEDESTRIAN\n",
       "56422     LARCENY-NON VEHICLE\n",
       "Name: UCR Literal, Length: 41513, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()# Should probably use OneHotEncoder instead\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/28656736/using-scikits-labelencoder-correctly-across-multiple-programs\n",
    "np.save('dl_classes.npy', encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 8, ..., 6, 8, 6])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41513, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_categorical.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "y_num_unique = y_train_categorical.shape[1]\n",
    "X_num_col = X_test_scaled.shape[1]\n",
    "model.add(Dense(units=100, activation='relu', input_dim=X_num_col))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=y_num_unique, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               1100      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 12,210\n",
      "Trainable params: 12,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1298/1298 [==============================] - 1s 671us/step - loss: 1.5415 - accuracy: 0.4483\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 2/60\n",
      "1298/1298 [==============================] - 1s 643us/step - loss: 1.3976 - accuracy: 0.5146\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 3/60\n",
      "1298/1298 [==============================] - 1s 607us/step - loss: 1.2481 - accuracy: 0.5910\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 4/60\n",
      "1298/1298 [==============================] - 1s 642us/step - loss: 1.1988 - accuracy: 0.6029\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 5/60\n",
      "1298/1298 [==============================] - 1s 654us/step - loss: 1.1889 - accuracy: 0.6089\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 6/60\n",
      "1298/1298 [==============================] - 1s 620us/step - loss: 1.1625 - accuracy: 0.6213\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 7/60\n",
      "1298/1298 [==============================] - 1s 620us/step - loss: 1.1538 - accuracy: 0.6206\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 8/60\n",
      "1298/1298 [==============================] - 1s 670us/step - loss: 1.1445 - accuracy: 0.6279\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 9/60\n",
      "1298/1298 [==============================] - 1s 603us/step - loss: 1.1412 - accuracy: 0.6250\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 10/60\n",
      "1298/1298 [==============================] - 1s 602us/step - loss: 1.1195 - accuracy: 0.6314\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 11/60\n",
      "1298/1298 [==============================] - 1s 618us/step - loss: 1.1166 - accuracy: 0.6302\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 12/60\n",
      "1298/1298 [==============================] - 1s 572us/step - loss: 1.1060 - accuracy: 0.6339\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 13/60\n",
      "1298/1298 [==============================] - 1s 555us/step - loss: 1.1092 - accuracy: 0.6331\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 14/60\n",
      "1298/1298 [==============================] - 1s 567us/step - loss: 1.0917 - accuracy: 0.6397\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 15/60\n",
      "1298/1298 [==============================] - 1s 563us/step - loss: 1.1024 - accuracy: 0.6360\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 16/60\n",
      "1298/1298 [==============================] - 1s 566us/step - loss: 1.0952 - accuracy: 0.6390\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 17/60\n",
      "1298/1298 [==============================] - 1s 556us/step - loss: 1.0899 - accuracy: 0.6409\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 18/60\n",
      "1298/1298 [==============================] - 1s 589us/step - loss: 1.0996 - accuracy: 0.6341\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 19/60\n",
      "1298/1298 [==============================] - 1s 555us/step - loss: 1.0890 - accuracy: 0.6380\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 20/60\n",
      "1298/1298 [==============================] - 1s 559us/step - loss: 1.0825 - accuracy: 0.6424\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 21/60\n",
      "1298/1298 [==============================] - 1s 564us/step - loss: 1.0853 - accuracy: 0.6392\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 22/60\n",
      "1298/1298 [==============================] - 1s 564us/step - loss: 1.0770 - accuracy: 0.6429\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 23/60\n",
      "1298/1298 [==============================] - 1s 613us/step - loss: 1.0756 - accuracy: 0.6431\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 24/60\n",
      "1298/1298 [==============================] - 1s 609us/step - loss: 1.0673 - accuracy: 0.6459\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 25/60\n",
      "1298/1298 [==============================] - 1s 560us/step - loss: 1.0710 - accuracy: 0.6433\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 26/60\n",
      "1298/1298 [==============================] - 1s 555us/step - loss: 1.0655 - accuracy: 0.6471\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 27/60\n",
      "1298/1298 [==============================] - 1s 567us/step - loss: 1.0647 - accuracy: 0.6473\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 28/60\n",
      "1298/1298 [==============================] - 1s 578us/step - loss: 1.0712 - accuracy: 0.6432\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 29/60\n",
      "1298/1298 [==============================] - 1s 555us/step - loss: 1.0652 - accuracy: 0.6441\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 30/60\n",
      "1298/1298 [==============================] - 1s 585us/step - loss: 1.0621 - accuracy: 0.6417\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 31/60\n",
      "1298/1298 [==============================] - 1s 598us/step - loss: 1.0590 - accuracy: 0.6461\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 32/60\n",
      "1298/1298 [==============================] - 1s 584us/step - loss: 1.0685 - accuracy: 0.6443\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 33/60\n",
      "1298/1298 [==============================] - 1s 557us/step - loss: 1.0529 - accuracy: 0.6521\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 34/60\n",
      "1298/1298 [==============================] - 1s 568us/step - loss: 1.0513 - accuracy: 0.6502\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 35/60\n",
      "1298/1298 [==============================] - 1s 567us/step - loss: 1.0376 - accuracy: 0.6553\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 36/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1298/1298 [==============================] - 1s 564us/step - loss: 1.0335 - accuracy: 0.6568\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 37/60\n",
      "1298/1298 [==============================] - 1s 552us/step - loss: 1.0352 - accuracy: 0.6574\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 38/60\n",
      "1298/1298 [==============================] - 1s 607us/step - loss: 1.0398 - accuracy: 0.6533\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 39/60\n",
      "1298/1298 [==============================] - 1s 560us/step - loss: 1.0354 - accuracy: 0.6521\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 40/60\n",
      "1298/1298 [==============================] - 1s 556us/step - loss: 1.0341 - accuracy: 0.6574\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 41/60\n",
      "1298/1298 [==============================] - 1s 546us/step - loss: 1.0449 - accuracy: 0.6507\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 42/60\n",
      "1298/1298 [==============================] - 1s 549us/step - loss: 1.0383 - accuracy: 0.6529\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 43/60\n",
      "1298/1298 [==============================] - 1s 551us/step - loss: 1.0345 - accuracy: 0.6572\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 44/60\n",
      "1298/1298 [==============================] - 1s 548us/step - loss: 1.0282 - accuracy: 0.6571\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 45/60\n",
      "1298/1298 [==============================] - 1s 611us/step - loss: 1.0410 - accuracy: 0.6504\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 46/60\n",
      "1298/1298 [==============================] - 1s 556us/step - loss: 1.0294 - accuracy: 0.6563\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 47/60\n",
      "1298/1298 [==============================] - 1s 551us/step - loss: 1.0250 - accuracy: 0.6563\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 48/60\n",
      "1298/1298 [==============================] - 1s 564us/step - loss: 1.0257 - accuracy: 0.6585\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 49/60\n",
      "1298/1298 [==============================] - 1s 557us/step - loss: 1.0283 - accuracy: 0.6573\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 50/60\n",
      "1298/1298 [==============================] - 1s 551us/step - loss: 1.0248 - accuracy: 0.6555\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 51/60\n",
      "1298/1298 [==============================] - 1s 569us/step - loss: 1.0268 - accuracy: 0.6572\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 52/60\n",
      "1298/1298 [==============================] - 1s 565us/step - loss: 1.0242 - accuracy: 0.6540\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 53/60\n",
      "1298/1298 [==============================] - 1s 549us/step - loss: 1.0179 - accuracy: 0.6591\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 54/60\n",
      "1298/1298 [==============================] - 1s 559us/step - loss: 1.0203 - accuracy: 0.6601\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 55/60\n",
      "1298/1298 [==============================] - 1s 553us/step - loss: 1.0203 - accuracy: 0.6614\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 56/60\n",
      "1298/1298 [==============================] - 1s 562us/step - loss: 1.0178 - accuracy: 0.6620\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 57/60\n",
      "1298/1298 [==============================] - 1s 556us/step - loss: 1.0209 - accuracy: 0.6610\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 58/60\n",
      "1298/1298 [==============================] - 1s 610us/step - loss: 1.0111 - accuracy: 0.6638\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 59/60\n",
      "1298/1298 [==============================] - 1s 557us/step - loss: 1.0102 - accuracy: 0.6629\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 60/60\n",
      "1298/1298 [==============================] - 1s 551us/step - loss: 1.0107 - accuracy: 0.6628\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x161551880>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set early stopping as callback\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=2)]\n",
    "#https://keras.rstudio.com/reference/fit.html\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    callbacks=callbacks, #List of `keras.callbacks.Callback` instances.\n",
    "    epochs=60, #Integer. Number of epochs to train the model.\n",
    "    shuffle=True,#Boolean (whether to shuffle the training data before each epoch)\n",
    "    verbose=1, #0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
    "    #view_metrics = 'auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "639/639 - 0s - loss: 1.0623 - accuracy: 0.6516\n",
      "Normal Neural Network - Loss: 1.0622973442077637, Accuracy: 0.6515551805496216\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BURGLARY-RESIDENCE', 'LARCENY-FROM VEHICLE', 'ROBBERY-PEDESTRIAN',\n",
       "       'LARCENY-FROM VEHICLE', 'LARCENY-FROM VEHICLE'], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_predictions = model.predict_classes(X_test_scaled[:5])\n",
    "prediction_labels = label_encoder.inverse_transform(encoded_predictions)\n",
    "prediction_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: ['BURGLARY-RESIDENCE' 'LARCENY-FROM VEHICLE' 'ROBBERY-PEDESTRIAN'\n",
      " 'LARCENY-FROM VEHICLE' 'LARCENY-FROM VEHICLE']\n",
      "Actual Labels: ['AUTO THEFT', 'LARCENY-FROM VEHICLE', 'ROBBERY-PEDESTRIAN', 'LARCENY-FROM VEHICLE', 'AUTO THEFT']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predicted classes: {prediction_labels}\")\n",
    "print(f\"Actual Labels: {list(y_test[:5])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('idklol.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beat</th>\n",
       "      <th>Occur Time</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Location Type</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Occur Year</th>\n",
       "      <th>Occur Month</th>\n",
       "      <th>Occur Day</th>\n",
       "      <th>Occur DayofWeek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36637</th>\n",
       "      <td>604.0</td>\n",
       "      <td>1630</td>\n",
       "      <td>4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>33.76142</td>\n",
       "      <td>-84.36492</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52369</th>\n",
       "      <td>505.0</td>\n",
       "      <td>1230</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>33.77448</td>\n",
       "      <td>-84.38263</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9562</th>\n",
       "      <td>505.0</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>33.77454</td>\n",
       "      <td>-84.37885</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21715</th>\n",
       "      <td>511.0</td>\n",
       "      <td>930</td>\n",
       "      <td>2</td>\n",
       "      <td>99.0</td>\n",
       "      <td>33.75281</td>\n",
       "      <td>-84.39197</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40637</th>\n",
       "      <td>604.0</td>\n",
       "      <td>2030</td>\n",
       "      <td>4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33.75772</td>\n",
       "      <td>-84.37067</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54343</th>\n",
       "      <td>503.0</td>\n",
       "      <td>1100</td>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33.78045</td>\n",
       "      <td>-84.38923</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38158</th>\n",
       "      <td>509.0</td>\n",
       "      <td>2250</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33.76020</td>\n",
       "      <td>-84.38554</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>208.0</td>\n",
       "      <td>1730</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>33.85166</td>\n",
       "      <td>-84.36235</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>512.0</td>\n",
       "      <td>2100</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33.75135</td>\n",
       "      <td>-84.39257</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56422</th>\n",
       "      <td>510.0</td>\n",
       "      <td>1830</td>\n",
       "      <td>2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>33.75513</td>\n",
       "      <td>-84.38216</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41513 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Beat  Occur Time  Neighborhood  Location Type  Latitude  Longitude  \\\n",
       "36637  604.0        1630             4           21.0  33.76142  -84.36492   \n",
       "52369  505.0        1230             3           13.0  33.77448  -84.38263   \n",
       "9562   505.0         200             3           13.0  33.77454  -84.37885   \n",
       "21715  511.0         930             2           99.0  33.75281  -84.39197   \n",
       "40637  604.0        2030             4           18.0  33.75772  -84.37067   \n",
       "...      ...         ...           ...            ...       ...        ...   \n",
       "54343  503.0        1100             3           18.0  33.78045  -84.38923   \n",
       "38158  509.0        2250             2           18.0  33.76020  -84.38554   \n",
       "860    208.0        1730             1            8.0  33.85166  -84.36235   \n",
       "15795  512.0        2100             2           18.0  33.75135  -84.39257   \n",
       "56422  510.0        1830             2           21.0  33.75513  -84.38216   \n",
       "\n",
       "       Occur Year  Occur Month  Occur Day  Occur DayofWeek  \n",
       "36637      2013.0         12.0       16.0              0.0  \n",
       "52369      2017.0          9.0        3.0              6.0  \n",
       "9562       2009.0          1.0        4.0              6.0  \n",
       "21715      2011.0          1.0       25.0              1.0  \n",
       "40637      2014.0         10.0       11.0              5.0  \n",
       "...           ...          ...        ...              ...  \n",
       "54343      2018.0          2.0       25.0              6.0  \n",
       "38158      2014.0          4.0       25.0              4.0  \n",
       "860        2009.0         12.0       10.0              3.0  \n",
       "15795      2009.0         12.0       16.0              2.0  \n",
       "56422      2018.0          9.0        7.0              4.0  \n",
       "\n",
       "[41513 rows x 10 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model = keras.models.load_model(\"idklol.h5\", compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled[:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BURGLARY-RESIDENCE'], dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_predictions = reconstructed_model.predict_classes(X_test_scaled[:1])\n",
    "prediction_labels = label_encoder.inverse_transform(encoded_predictions)\n",
    "prediction_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_scaled[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20448, 10)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_categorical.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_idk = [604.0, 1630.0, 0.0, 21.0, 33.76142, -84.36492, 2013.0, 12.0, 16.0, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'float'>\"}), <class 'numpy.ndarray'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-26020a8f39a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreconstructed_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_idk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_categorical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1048\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m       \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[1;32m   1051\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m           \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1097\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m     self._adapter = adapter_cls(\n\u001b[1;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    959\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m     \u001b[0;31m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m    962\u001b[0m         \u001b[0;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m         \"input: {}, {}\".format(\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'float'>\"}), <class 'numpy.ndarray'>"
     ]
    }
   ],
   "source": [
    "reconstructed_model.fit(X_idk, y_test_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.0293841e-02, 6.7632861e-02, 6.3553505e-02, ..., 1.0734848e-03,\n",
       "        2.0735484e-02, 4.7921063e-03],\n",
       "       [2.2807231e-02, 1.7564954e-01, 6.1571929e-03, ..., 6.4032042e-04,\n",
       "        3.9618213e-02, 1.9632773e-04],\n",
       "       [4.4283237e-02, 1.7627788e-01, 7.3368479e-03, ..., 3.1975575e-04,\n",
       "        2.6015604e-01, 4.5181164e-03],\n",
       "       ...,\n",
       "       [2.2007364e-03, 9.4439974e-03, 8.3655536e-02, ..., 1.9120175e-03,\n",
       "        3.1855304e-03, 7.3849129e-05],\n",
       "       [1.7056884e-02, 1.1190084e-01, 2.0748987e-03, ..., 6.0069910e-04,\n",
       "        5.9603840e-02, 1.0715683e-04],\n",
       "       [9.1480598e-02, 3.2791860e-02, 6.7437552e-02, ..., 4.7420827e-03,\n",
       "        2.3778971e-02, 8.7832976e-03]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstructed_model.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98046875, 0.67916667, 1.        , 0.20408163, 0.11941612,\n",
       "       0.69499632, 0.4       , 1.        , 0.5       , 0.        ])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.3977187e-02, 9.8951019e-02, 5.1365569e-02, ..., 1.3484752e-03,\n",
       "        2.2583222e-02, 1.6335694e-02],\n",
       "       [3.7965398e-02, 1.7636184e-01, 1.1915312e-02, ..., 5.2821124e-03,\n",
       "        5.4536778e-02, 1.2400452e-04],\n",
       "       [6.8766430e-02, 1.4051265e-01, 3.5233505e-03, ..., 1.9072044e-04,\n",
       "        3.9176857e-01, 2.1653804e-03],\n",
       "       ...,\n",
       "       [1.6988408e-03, 4.0298337e-03, 2.1566374e-02, ..., 9.8411564e-04,\n",
       "        7.7598817e-03, 3.3084507e-04],\n",
       "       [1.9098999e-02, 1.1138725e-01, 2.0083312e-03, ..., 7.0399925e-04,\n",
       "        5.1027413e-02, 1.2447864e-04],\n",
       "       [5.7612672e-02, 3.1706065e-02, 4.0009890e-02, ..., 5.0631310e-03,\n",
       "        2.1363162e-02, 5.8322512e-03]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
