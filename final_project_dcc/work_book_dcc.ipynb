{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "lined-division",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.7\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "furnished-colorado",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://crime-data-explorer.app.cloud.gov/explorer/state/georgia/crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "renewable-privacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np, sys, time, pdb, matplotlib.pyplot as plt\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ideal-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)# None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "moderate-monte",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2020 = pd.read_csv('./flask/static/data/COBRA-2020.csv')\n",
    "data_2021 = pd.read_csv('./flask/static/data/COBRA-2021.csv')\n",
    "data_2009_2019 = pd.read_csv('./flask/static/data/COBRA-2009-2019.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "moderate-overhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2020_list = data_2020.columns.values.tolist()\n",
    "data_2021_list = data_2021.columns.values.tolist()\n",
    "data_2009_2019_list = data_2009_2019.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "tracked-confirmation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offense_id</th>\n",
       "      <th>rpt_date</th>\n",
       "      <th>occur_date</th>\n",
       "      <th>occur_time</th>\n",
       "      <th>poss_date</th>\n",
       "      <th>poss_time</th>\n",
       "      <th>beat</th>\n",
       "      <th>apt_office_prefix</th>\n",
       "      <th>apt_office_num</th>\n",
       "      <th>location</th>\n",
       "      <th>MinOfucr</th>\n",
       "      <th>dispo_code</th>\n",
       "      <th>Shift</th>\n",
       "      <th>loc_type</th>\n",
       "      <th>UC2_Literal</th>\n",
       "      <th>ibr_code</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>npu</th>\n",
       "      <th>long</th>\n",
       "      <th>lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>203341346</td>\n",
       "      <td>12/31/2020</td>\n",
       "      <td>11/29/2020</td>\n",
       "      <td>19:21</td>\n",
       "      <td>11/29/2020</td>\n",
       "      <td>23:50</td>\n",
       "      <td>405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3050 M.L.K. JR DR SW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AGG ASSAULT</td>\n",
       "      <td>13A</td>\n",
       "      <td>Harland Terrace</td>\n",
       "      <td>I</td>\n",
       "      <td>-84.486163</td>\n",
       "      <td>33.75106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offense_id    rpt_date  occur_date occur_time   poss_date poss_time beat  \\\n",
       "0   203341346  12/31/2020  11/29/2020      19:21  11/29/2020     23:50  405   \n",
       "\n",
       "   apt_office_prefix  apt_office_num              location  MinOfucr  \\\n",
       "0                NaN             NaN  3050 M.L.K. JR DR SW       NaN   \n",
       "\n",
       "   dispo_code  Shift  loc_type  UC2_Literal ibr_code     neighborhood npu  \\\n",
       "0         NaN    NaN       NaN  AGG ASSAULT      13A  Harland Terrace   I   \n",
       "\n",
       "        long       lat  \n",
       "0 -84.486163  33.75106  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data_2020_list))\n",
    "data_2020.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "educational-calendar",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Report Number</th>\n",
       "      <th>Report Date</th>\n",
       "      <th>Occur Date</th>\n",
       "      <th>Occur Time</th>\n",
       "      <th>Possible Date</th>\n",
       "      <th>Possible Time</th>\n",
       "      <th>Beat</th>\n",
       "      <th>Apartment Office Prefix</th>\n",
       "      <th>Apartment Number</th>\n",
       "      <th>Location</th>\n",
       "      <th>Shift Occurence</th>\n",
       "      <th>Location Type</th>\n",
       "      <th>UCR Literal</th>\n",
       "      <th>UCR #</th>\n",
       "      <th>IBR Code</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>NPU</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>342904</th>\n",
       "      <td>193651605</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>1615</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>1745.0</td>\n",
       "      <td>507.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180 WALKER ST SW</td>\n",
       "      <td>Evening Watch</td>\n",
       "      <td>18</td>\n",
       "      <td>LARCENY-FROM VEHICLE</td>\n",
       "      <td>640</td>\n",
       "      <td>2305</td>\n",
       "      <td>Castleberry Hill</td>\n",
       "      <td>M</td>\n",
       "      <td>33.74964</td>\n",
       "      <td>-84.40132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342905</th>\n",
       "      <td>193651845</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>1855</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>1915.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99 KROG ST NE</td>\n",
       "      <td>Morning Watch</td>\n",
       "      <td>18</td>\n",
       "      <td>LARCENY-FROM VEHICLE</td>\n",
       "      <td>640</td>\n",
       "      <td>2305</td>\n",
       "      <td>Inman Park</td>\n",
       "      <td>N</td>\n",
       "      <td>33.75667</td>\n",
       "      <td>-84.36390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342906</th>\n",
       "      <td>193652247</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2130</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2132.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>992 PEACHTREE ST NE</td>\n",
       "      <td>Evening Watch</td>\n",
       "      <td>13</td>\n",
       "      <td>LARCENY-FROM VEHICLE</td>\n",
       "      <td>640</td>\n",
       "      <td>2305</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>E</td>\n",
       "      <td>33.78192</td>\n",
       "      <td>-84.38410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342907</th>\n",
       "      <td>193652287</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2101.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1371 MARKET ST NW</td>\n",
       "      <td>Evening Watch</td>\n",
       "      <td>18</td>\n",
       "      <td>LARCENY-FROM VEHICLE</td>\n",
       "      <td>640</td>\n",
       "      <td>2305</td>\n",
       "      <td>Atlantic Station</td>\n",
       "      <td>E</td>\n",
       "      <td>33.79210</td>\n",
       "      <td>-84.39466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342908</th>\n",
       "      <td>193642145</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>2001</td>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>2157.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1085 HOWELL MILL RD NW</td>\n",
       "      <td>Evening Watch</td>\n",
       "      <td>18</td>\n",
       "      <td>LARCENY-FROM VEHICLE</td>\n",
       "      <td>640</td>\n",
       "      <td>2305</td>\n",
       "      <td>Home Park</td>\n",
       "      <td>E</td>\n",
       "      <td>33.78455</td>\n",
       "      <td>-84.41142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342909</th>\n",
       "      <td>193652089</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2030</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2034.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1385 SHARON ST NW</td>\n",
       "      <td>Morning Watch</td>\n",
       "      <td>20</td>\n",
       "      <td>AGG ASSAULT</td>\n",
       "      <td>420</td>\n",
       "      <td>1315K</td>\n",
       "      <td>Hunter Hills</td>\n",
       "      <td>K</td>\n",
       "      <td>33.75486</td>\n",
       "      <td>-84.43287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342910</th>\n",
       "      <td>193650336</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>0432</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>432.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>262 PHARR RD NE</td>\n",
       "      <td>Morning Watch</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AGG ASSAULT</td>\n",
       "      <td>410</td>\n",
       "      <td>1314</td>\n",
       "      <td>Buckhead Village</td>\n",
       "      <td>B</td>\n",
       "      <td>33.83732</td>\n",
       "      <td>-84.37860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342911</th>\n",
       "      <td>193650603</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>0920</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>940.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>689 CASCADE AVE SW</td>\n",
       "      <td>Day Watch</td>\n",
       "      <td>18</td>\n",
       "      <td>AGG ASSAULT</td>\n",
       "      <td>410</td>\n",
       "      <td>1314</td>\n",
       "      <td>Westview</td>\n",
       "      <td>T</td>\n",
       "      <td>33.73636</td>\n",
       "      <td>-84.43680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342912</th>\n",
       "      <td>193651760</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>1853</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>763 CASCADE AVE SW</td>\n",
       "      <td>Evening Watch</td>\n",
       "      <td>26</td>\n",
       "      <td>AGG ASSAULT</td>\n",
       "      <td>410</td>\n",
       "      <td>1314</td>\n",
       "      <td>Westview</td>\n",
       "      <td>T</td>\n",
       "      <td>33.73483</td>\n",
       "      <td>-84.43750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342913</th>\n",
       "      <td>193652591</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2045</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2055.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>237 PEYTON PL SW</td>\n",
       "      <td>Evening Watch</td>\n",
       "      <td>20</td>\n",
       "      <td>AGG ASSAULT</td>\n",
       "      <td>410</td>\n",
       "      <td>1314</td>\n",
       "      <td>Cascade Avenue/Road</td>\n",
       "      <td>S</td>\n",
       "      <td>33.72518</td>\n",
       "      <td>-84.45013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Report Number Report Date  Occur Date Occur Time Possible Date  \\\n",
       "342904      193651605  2019-12-31  2019-12-31       1615    2019-12-31   \n",
       "342905      193651845  2019-12-31  2019-12-31       1855    2019-12-31   \n",
       "342906      193652247  2019-12-31  2019-12-31       2130    2019-12-31   \n",
       "342907      193652287  2019-12-31  2019-12-31       2000    2019-12-31   \n",
       "342908      193642145  2019-12-31  2019-12-30       2001    2019-12-30   \n",
       "342909      193652089  2019-12-31  2019-12-31       2030    2019-12-31   \n",
       "342910      193650336  2019-12-31  2019-12-31       0432    2019-12-31   \n",
       "342911      193650603  2019-12-31  2019-12-31       0920    2019-12-31   \n",
       "342912      193651760  2019-12-31  2019-12-31       1853    2019-12-31   \n",
       "342913      193652591  2019-12-31  2019-12-31       2045    2019-12-31   \n",
       "\n",
       "        Possible Time   Beat Apartment Office Prefix Apartment Number  \\\n",
       "342904         1745.0  507.0                     NaN              NaN   \n",
       "342905         1915.0  602.0                     NaN              NaN   \n",
       "342906         2132.0  503.0                     NaN              NaN   \n",
       "342907         2101.0  501.0                     NaN              NaN   \n",
       "342908         2157.0  501.0                     NaN              NaN   \n",
       "342909         2034.0  105.0                     NaN              NaN   \n",
       "342910          432.0  206.0                     NaN              NaN   \n",
       "342911          940.0  404.0                     NaN              NaN   \n",
       "342912         1900.0  404.0                     NaN              NaN   \n",
       "342913         2055.0  406.0                     NaN              NaN   \n",
       "\n",
       "                      Location Shift Occurence Location Type  \\\n",
       "342904        180 WALKER ST SW   Evening Watch            18   \n",
       "342905          99 KROG ST NE    Morning Watch            18   \n",
       "342906     992 PEACHTREE ST NE   Evening Watch            13   \n",
       "342907       1371 MARKET ST NW   Evening Watch            18   \n",
       "342908  1085 HOWELL MILL RD NW   Evening Watch            18   \n",
       "342909       1385 SHARON ST NW   Morning Watch            20   \n",
       "342910         262 PHARR RD NE   Morning Watch           NaN   \n",
       "342911      689 CASCADE AVE SW       Day Watch            18   \n",
       "342912      763 CASCADE AVE SW   Evening Watch            26   \n",
       "342913        237 PEYTON PL SW   Evening Watch            20   \n",
       "\n",
       "                 UCR Literal  UCR # IBR Code         Neighborhood NPU  \\\n",
       "342904  LARCENY-FROM VEHICLE    640     2305     Castleberry Hill   M   \n",
       "342905  LARCENY-FROM VEHICLE    640     2305           Inman Park   N   \n",
       "342906  LARCENY-FROM VEHICLE    640     2305              Midtown   E   \n",
       "342907  LARCENY-FROM VEHICLE    640     2305     Atlantic Station   E   \n",
       "342908  LARCENY-FROM VEHICLE    640     2305            Home Park   E   \n",
       "342909           AGG ASSAULT    420    1315K         Hunter Hills   K   \n",
       "342910           AGG ASSAULT    410     1314     Buckhead Village   B   \n",
       "342911           AGG ASSAULT    410     1314             Westview   T   \n",
       "342912           AGG ASSAULT    410     1314             Westview   T   \n",
       "342913           AGG ASSAULT    410     1314  Cascade Avenue/Road   S   \n",
       "\n",
       "        Latitude  Longitude  \n",
       "342904  33.74964  -84.40132  \n",
       "342905  33.75667  -84.36390  \n",
       "342906  33.78192  -84.38410  \n",
       "342907  33.79210  -84.39466  \n",
       "342908  33.78455  -84.41142  \n",
       "342909  33.75486  -84.43287  \n",
       "342910  33.83732  -84.37860  \n",
       "342911  33.73636  -84.43680  \n",
       "342912  33.73483  -84.43750  \n",
       "342913  33.72518  -84.45013  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data_2009_2019_list))\n",
    "data_2009_2019.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "renewable-alexander",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Report Number</th>\n",
       "      <th>Report Date</th>\n",
       "      <th>Occur Date</th>\n",
       "      <th>Occur Time</th>\n",
       "      <th>Possible Date</th>\n",
       "      <th>Possible Time</th>\n",
       "      <th>Beat</th>\n",
       "      <th>Apartment Office Prefix</th>\n",
       "      <th>Apartment Number</th>\n",
       "      <th>Location</th>\n",
       "      <th>Shift Occurence</th>\n",
       "      <th>Location Type</th>\n",
       "      <th>UCR Literal</th>\n",
       "      <th>IBR Code</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>NPU</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>203341346</td>\n",
       "      <td>12/31/2020</td>\n",
       "      <td>11/29/2020</td>\n",
       "      <td>19:21</td>\n",
       "      <td>11/29/2020</td>\n",
       "      <td>23:50</td>\n",
       "      <td>405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3050 M.L.K. JR DR SW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AGG ASSAULT</td>\n",
       "      <td>13A</td>\n",
       "      <td>Harland Terrace</td>\n",
       "      <td>I</td>\n",
       "      <td>-84.486163</td>\n",
       "      <td>33.75106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Report Number Report Date  Occur Date Occur Time Possible Date  \\\n",
       "0      203341346  12/31/2020  11/29/2020      19:21    11/29/2020   \n",
       "\n",
       "  Possible Time Beat  Apartment Office Prefix  Apartment Number  \\\n",
       "0         23:50  405                      NaN               NaN   \n",
       "\n",
       "               Location  Shift Occurence  Location Type  UCR Literal IBR Code  \\\n",
       "0  3050 M.L.K. JR DR SW              NaN            NaN  AGG ASSAULT      13A   \n",
       "\n",
       "      Neighborhood NPU  Longitude  Latitude  \n",
       "0  Harland Terrace   I -84.486163  33.75106  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since the 2009-2019 dataset is the largest, everything will try and have the same columns as that dataset\n",
    "data_2020.rename(columns = {\n",
    " 'offense_id' : 'Report Number',\n",
    " 'rpt_date' : 'Report Date',\n",
    " 'occur_date' : 'Occur Date',\n",
    " 'occur_time' : 'Occur Time',\n",
    " 'poss_date' : 'Possible Date',\n",
    " 'poss_time' : 'Possible Time',\n",
    " 'beat' : 'Beat',\n",
    " 'apt_office_prefix' : 'Apartment Office Prefix',\n",
    " 'apt_office_num' : 'Apartment Number',\n",
    " 'location' : 'Location',\n",
    " #'MinOfucr' : ,\n",
    " #'dispo_code' : ,\n",
    " 'Shift' : 'Shift Occurence',\n",
    " 'loc_type' : 'Location Type',\n",
    " 'UC2_Literal': 'UCR Literal',\n",
    " 'ibr_code' : 'IBR Code',\n",
    " 'neighborhood' : 'Neighborhood',\n",
    " 'npu' : 'NPU',\n",
    " 'long' : 'Longitude',\n",
    " 'lat' : 'Latitude'\n",
    "}, inplace = True)\n",
    "#Drop columns that do not seem to show up in 2009-2019 dataset\n",
    "data_2020 = data_2020.drop(columns=['MinOfucr','dispo_code'])\n",
    "data_2020.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "imposed-portable",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['UCR #']\n"
     ]
    }
   ],
   "source": [
    "list1 = data_2009_2019.columns.values.tolist()\n",
    "list2 = data_2020.columns.values.tolist()\n",
    "\n",
    "list_difference = [item for item in list1 if item not in list2]\n",
    "print(list_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "governing-elements",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It can be seen that the 'UCR #' shows up only in the 2009-2019 data and realistically serves no purpose because its a code only a cop would udnerstand\n",
    "#So it should be droped to simplify\n",
    "data_2009_2019 = data_2009_2019.drop(columns=['UCR #'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "respective-moldova",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "list1 = data_2009_2019.columns.values.tolist()\n",
    "list2 = data_2020.columns.values.tolist()\n",
    "\n",
    "list_difference = [item for item in list1 if item not in list2]\n",
    "print(list_difference)\n",
    "#There should now be no differences as at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "centered-midwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concat the dataframes together\n",
    "data = pd.concat([data_2009_2019, data_2020])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "affected-edward",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2009_2019['Occur Date'].sort_values();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "impressive-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Report Date'] = pd.to_datetime(data['Report Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "referenced-violence",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data.csv')\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "#data.to_json('data.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-hampton",
   "metadata": {},
   "source": [
    "# Decrease Data by Reducing Number of Neighborhods\n",
    "It has become apparent that there is too mach data and our relatively weak computers are not up to the challenge give the time.\n",
    "\n",
    "It was decided to just look at 5 major \"Neighborhood\" of interest:\n",
    "\n",
    "buckhead, midtown, brookhaven, downtown, old fourth ward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "varying-vanilla",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3155: DtypeWarning: Columns (4,6,7,12) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data.csv\")\n",
    "df_reduced = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "compressed-sterling",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced[\"Neighborhood\"].unique();\n",
    "#Used to show all rows for error checking\n",
    "#pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "final-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_buckhead = df_reduced[(df_reduced[\"Neighborhood\"] == \"Buckhead Forest\") |(df_reduced[\"Neighborhood\"] == \"Buckhead Village\")\n",
    "           |(df_reduced[\"Neighborhood\"] == \"North Buckhead\") |(df_reduced[\"Neighborhood\"] == \"Buckhead Heights\")\n",
    "          ]\n",
    "df_buckhead\n",
    "df_buckhead['Neighborhood']\n",
    "\n",
    "df_buckhead = df_buckhead.assign(Neighborhood = 'Buckhead' )\n",
    "df_buckhead\n",
    "\n",
    "df_other_hoods  = df_reduced[(df_reduced[\"Neighborhood\"] == \"Midtown\") | (df_reduced[\"Neighborhood\"] == \"Brookhaven\")\n",
    "          |(df_reduced[\"Neighborhood\"] == \"Downtown\") | (df_reduced[\"Neighborhood\"] == \"Old Fourth Ward\")]\n",
    "df_other_hoods\n",
    "\n",
    "df_5hoods = pd.concat([df_buckhead,df_other_hoods], ignore_index=True, sort=False)\n",
    "df_5hoods\n",
    "\n",
    "df_5hoods = df_5hoods.drop(columns=['Unnamed: 0'])\n",
    "df_5hoods.to_csv('data_5hoods.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-hypothesis",
   "metadata": {},
   "source": [
    "# Seperate out the Date and Time Columns\n",
    "\n",
    "Need to make the columns a datetime formate and then seperate at useful information such as year, month, day, day of the week and make sure they are all in some sort of numerical formatting that would make sense in MachinLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "acute-organ",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3155: DtypeWarning: Columns (7,8,10,11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data_5hoods.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "laden-kernel",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Occur Date'] = pd.to_datetime(df['Occur Date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "demonstrated-universal",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Occur Year'] = pd.DatetimeIndex(df['Occur Date']).year\n",
    "df['Occur Month'] = pd.DatetimeIndex(df['Occur Date']).month\n",
    "df['Occur Day'] = pd.DatetimeIndex(df['Occur Date']).day\n",
    "df['Occur DayofWeek'] = pd.DatetimeIndex(df['Occur Date']).dayofweek#Already sets to a numerical for onehotencoding later\n",
    "df = df.dropna(subset=['Occur Year'], how='all')\n",
    "df = df[~(df['Occur Year'] <= 2008)]\n",
    "df.sort_values(by=['Occur Year']).head(100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "fluid-protein",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Occur Time'] = pd.to_datetime(df['Occur Time'], errors='coerce')\n",
    "df = df[~df['Occur Time'].str.contains(\":\")]\n",
    "df = df[~df['Location Type'].str.contains(r\"[a-zA-Z]\",na=False)]#Drop the weird nonnumeric character that is in a few"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "removable-andorra",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"Location Type\"] = pd.to_numeric(df[\"Location Type\"])\n",
    "df = df.dropna(subset=['Location Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "devoted-mineral",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data_5hoods_datetime.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-animal",
   "metadata": {},
   "source": [
    "# Machine Learnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silver-booking",
   "metadata": {},
   "source": [
    "## Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-arrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\")\n",
    "# Drop the null columns where all values are null\n",
    "#df = df.dropna(axis='columns', how='all')\n",
    "# Drop the null rows\n",
    "df = df[[\"Latitude\",\"Longitude\",\"Neighborhood\"]]\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "former-concrete",
   "metadata": {},
   "source": [
    "## Create a Train Test Split\n",
    "\n",
    "Use `Neighborhood` for the y values\n",
    "This can be an idiot check to see if lat an lon can predict neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-upper",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = df[\"Neighborhood\"]\n",
    "X = df.drop(columns=[\"Neighborhood\"])\n",
    "\n",
    "#For example, if variable y is a binary categorical variable with values 0 and 1 and there are 25% of zeros and 75% of ones, stratify=y will make sure that your random split has 25% of 0's and 75% of 1's.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-hamilton",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "rental-notion",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-repository",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_scaler = MinMaxScaler().fit(X_train)#Compute the minimum and maximum to be used for later scaling.\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)#Scale features of X_train according to feature_range.\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-belly",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-subscription",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-stations",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-reach",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train_scaled, y_train)# Fit the LR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-crime",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-spanish",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Data Score: {model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {model.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-institute",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler.transform(X_train)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-cedar",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-gnome",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-briefs",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Use `GridSearchCV` to tune the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-texas",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Cfloat, default=1.0 Inverse of regularization strength; must be a positive float. Like in support vector machines, smaller values specify stronger regularization.\n",
    "# penalty{‘l1’, ‘l2’, ‘elasticnet’, ‘none’}, default=’l2’\n",
    "param_grid = {'C': [1, 3,5,7,9],\n",
    "              'penalty': [\"l1\", \"l2\", \"none\"]}\n",
    "Model = LogisticRegression(solver='liblinear')\n",
    "grid = GridSearchCV(Model, param_grid, verbose=3)\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-probe",
   "metadata": {},
   "outputs": [],
   "source": [
    "idk = grid.fit(X_train_scaled, y_train)\n",
    "idk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-tracker",
   "metadata": {},
   "source": [
    "# Machine Learnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "fleet-commission",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data_5hoods_datetime.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "processed-corpus",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "earlier-pocket",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Select columns of interst\n",
    "df = df[[\"Beat\",\n",
    "    \"Occur Time\",\n",
    "    \"Neighborhood\",\n",
    "    \"Location Type\",\n",
    "    \"Latitude\",\n",
    "    \"Longitude\",\n",
    "    \"Occur Year\",\n",
    "    \"Occur Month\",\n",
    "    \"Occur Day\",\n",
    "    \"Occur DayofWeek\",\n",
    "    \"UCR Literal\"]]\n",
    "#df.dropna(subset=['Location Type', 'Occur Time'])\n",
    "df.dropna(subset=['Beat'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "fabulous-hampshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer \n",
    "y = df[\"UCR Literal\"]\n",
    "X = df.drop(columns=[\"UCR Literal\"])\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder() \n",
    "X['Neighborhood']= le.fit_transform(X['Neighborhood']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "union-coordination",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For example, if variable y is a binary categorical variable with values 0 and 1 and there are 25% of zeros and 75% of ones, stratify=y will make sure that your random split has 25% of 0's and 75% of 1's.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "threaded-chamber",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beat</th>\n",
       "      <th>Occur Time</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Location Type</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Occur Year</th>\n",
       "      <th>Occur Month</th>\n",
       "      <th>Occur Day</th>\n",
       "      <th>Occur DayofWeek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58111</th>\n",
       "      <td>102.0</td>\n",
       "      <td>2330</td>\n",
       "      <td>2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>33.76951</td>\n",
       "      <td>-84.38527</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60324</th>\n",
       "      <td>201.0</td>\n",
       "      <td>445</td>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>33.75657</td>\n",
       "      <td>-84.38034</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8624</th>\n",
       "      <td>206.0</td>\n",
       "      <td>1630</td>\n",
       "      <td>1</td>\n",
       "      <td>99.0</td>\n",
       "      <td>33.84008</td>\n",
       "      <td>-84.37231</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6092</th>\n",
       "      <td>206.0</td>\n",
       "      <td>1530</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33.83790</td>\n",
       "      <td>-84.37852</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>206.0</td>\n",
       "      <td>1545</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>33.83852</td>\n",
       "      <td>-84.38007</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38022</th>\n",
       "      <td>614.0</td>\n",
       "      <td>2150</td>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33.77909</td>\n",
       "      <td>-84.36717</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50904</th>\n",
       "      <td>614.0</td>\n",
       "      <td>2130</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>33.77604</td>\n",
       "      <td>-84.37739</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45026</th>\n",
       "      <td>614.0</td>\n",
       "      <td>1830</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>33.77749</td>\n",
       "      <td>-84.37164</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18980</th>\n",
       "      <td>614.0</td>\n",
       "      <td>830</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>33.77873</td>\n",
       "      <td>-84.37368</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31574</th>\n",
       "      <td>614.0</td>\n",
       "      <td>1930</td>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33.77940</td>\n",
       "      <td>-84.37587</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41513 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Beat  Occur Time  Neighborhood  Location Type  Latitude  Longitude  \\\n",
       "58111  102.0        2330             2           28.0  33.76951  -84.38527   \n",
       "60324  201.0         445             2           26.0  33.75657  -84.38034   \n",
       "8624   206.0        1630             1           99.0  33.84008  -84.37231   \n",
       "6092   206.0        1530             1           18.0  33.83790  -84.37852   \n",
       "9090   206.0        1545             1            8.0  33.83852  -84.38007   \n",
       "...      ...         ...           ...            ...       ...        ...   \n",
       "38022  614.0        2150             3           18.0  33.77909  -84.36717   \n",
       "50904  614.0        2130             3            7.0  33.77604  -84.37739   \n",
       "45026  614.0        1830             3           13.0  33.77749  -84.37164   \n",
       "18980  614.0         830             3           13.0  33.77873  -84.37368   \n",
       "31574  614.0        1930             3           18.0  33.77940  -84.37587   \n",
       "\n",
       "       Occur Year  Occur Month  Occur Day  Occur DayofWeek  \n",
       "58111      2019.0          2.0        4.0              0.0  \n",
       "60324      2019.0          8.0       26.0              0.0  \n",
       "8624       2018.0         12.0       22.0              5.0  \n",
       "6092       2016.0          3.0       15.0              1.0  \n",
       "9090       2019.0          7.0       25.0              3.0  \n",
       "...           ...          ...        ...              ...  \n",
       "38022      2014.0          4.0       13.0              6.0  \n",
       "50904      2017.0          4.0       17.0              0.0  \n",
       "45026      2015.0          9.0       25.0              4.0  \n",
       "18980      2010.0          7.0       25.0              6.0  \n",
       "31574      2012.0         12.0       14.0              4.0  \n",
       "\n",
       "[41513 rows x 10 columns]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.sort_values(['Beat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "precise-moses",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_scaler = MinMaxScaler().fit(X_train)#Compute the minimum and maximum to be used for later scaling.\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)#Scale features of X_train according to feature_range.\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "developed-kenya",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(solver='liblinear'),\n",
       "             param_grid={'C': [6, 7, 11], 'penalty': ['l1', 'l2', 'none']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Cfloat, default=1.0 Inverse of regularization strength; must be a positive float. Like in support vector machines, smaller values specify stronger regularization.\n",
    "# penalty{‘l1’, ‘l2’, ‘elasticnet’, ‘none’}, default=’l2’\n",
    "param_grid = {'C': [6,7,11],\n",
    "              'penalty': [\"l1\", \"l2\", \"none\"]}\n",
    "Model = LogisticRegression(solver='liblinear')\n",
    "grid = GridSearchCV(Model, param_grid, verbose=1)\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "distinguished-freedom",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5] END ................................C=6, penalty=l1; total time=  10.6s\n",
      "[CV 2/5] END ................................C=6, penalty=l1; total time=   9.1s\n",
      "[CV 3/5] END ................................C=6, penalty=l1; total time=   9.4s\n",
      "[CV 4/5] END ................................C=6, penalty=l1; total time=   8.7s\n",
      "[CV 5/5] END ................................C=6, penalty=l1; total time=  10.2s\n",
      "[CV 1/5] END ................................C=6, penalty=l2; total time=   0.7s\n",
      "[CV 2/5] END ................................C=6, penalty=l2; total time=   0.8s\n",
      "[CV 3/5] END ................................C=6, penalty=l2; total time=   0.7s\n",
      "[CV 4/5] END ................................C=6, penalty=l2; total time=   0.7s\n",
      "[CV 5/5] END ................................C=6, penalty=l2; total time=   0.8s\n",
      "[CV 1/5] END ..............................C=6, penalty=none; total time=   0.0s\n",
      "[CV 2/5] END ..............................C=6, penalty=none; total time=   0.0s\n",
      "[CV 3/5] END ..............................C=6, penalty=none; total time=   0.0s\n",
      "[CV 4/5] END ..............................C=6, penalty=none; total time=   0.0s\n",
      "[CV 5/5] END ..............................C=6, penalty=none; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ................................C=7, penalty=l1; total time=  10.3s\n",
      "[CV 2/5] END ................................C=7, penalty=l1; total time=   9.1s\n",
      "[CV 3/5] END ................................C=7, penalty=l1; total time=   9.6s\n",
      "[CV 4/5] END ................................C=7, penalty=l1; total time=   9.4s\n",
      "[CV 5/5] END ................................C=7, penalty=l1; total time=  10.8s\n",
      "[CV 1/5] END ................................C=7, penalty=l2; total time=   0.7s\n",
      "[CV 2/5] END ................................C=7, penalty=l2; total time=   0.7s\n",
      "[CV 3/5] END ................................C=7, penalty=l2; total time=   0.7s\n",
      "[CV 4/5] END ................................C=7, penalty=l2; total time=   0.7s\n",
      "[CV 5/5] END ................................C=7, penalty=l2; total time=   0.7s\n",
      "[CV 1/5] END ..............................C=7, penalty=none; total time=   0.0s\n",
      "[CV 2/5] END ..............................C=7, penalty=none; total time=   0.0s\n",
      "[CV 3/5] END ..............................C=7, penalty=none; total time=   0.0s\n",
      "[CV 4/5] END ..............................C=7, penalty=none; total time=   0.0s\n",
      "[CV 5/5] END ..............................C=7, penalty=none; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...............................C=11, penalty=l1; total time=  10.0s\n",
      "[CV 2/5] END ...............................C=11, penalty=l1; total time=  10.2s\n",
      "[CV 3/5] END ...............................C=11, penalty=l1; total time=   9.8s\n",
      "[CV 4/5] END ...............................C=11, penalty=l1; total time=  10.1s\n",
      "[CV 5/5] END ...............................C=11, penalty=l1; total time=   9.9s\n",
      "[CV 1/5] END ...............................C=11, penalty=l2; total time=   0.8s\n",
      "[CV 2/5] END ...............................C=11, penalty=l2; total time=   0.7s\n",
      "[CV 3/5] END ...............................C=11, penalty=l2; total time=   0.7s\n",
      "[CV 4/5] END ...............................C=11, penalty=l2; total time=   0.7s\n",
      "[CV 5/5] END ...............................C=11, penalty=l2; total time=   0.7s\n",
      "[CV 1/5] END .............................C=11, penalty=none; total time=   0.0s\n",
      "[CV 2/5] END .............................C=11, penalty=none; total time=   0.0s\n",
      "[CV 3/5] END .............................C=11, penalty=none; total time=   0.0s\n",
      "[CV 4/5] END .............................C=11, penalty=none; total time=   0.0s\n",
      "[CV 5/5] END .............................C=11, penalty=none; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.46000054 0.45997645        nan 0.45997645 0.45997645        nan\n",
      " 0.45997645 0.45997645        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(solver='liblinear'),\n",
       "             param_grid={'C': [6, 7, 11], 'penalty': ['l1', 'l2', 'none']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "contrary-acrobat",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 6, 'penalty': 'l1'}\n",
      "0.4600005402464295\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-shoulder",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-boutique",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save fitted model to file\n",
    "# In the specific case of scikit-learn, it may be better to use joblib’s replacement of\n",
    "# pickle (dump & load), which is more efficient on objects that carry large numpy arrays\n",
    "# internally as is often the case for fitted scikit-learn estimators, but can only pickle\n",
    "# to the disk and not to a string:\n",
    "\n",
    "import joblib\n",
    "filename = 'five_hoods_LR.sav'\n",
    "joblib.dump(grid, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifth-annotation",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-inventory",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = joblib.load(\"five_hoods_LR.sav\")\n",
    "Model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-halifax",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
