{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data_5hoods_datetime.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select columns of interst\n",
    "df = df[[\"Beat\",\n",
    "    \"Occur Time\",\n",
    "    \"Neighborhood\",\n",
    "    \"Location Type\",\n",
    "    \"Latitude\",\n",
    "    \"Longitude\",\n",
    "    \"Occur Year\",\n",
    "    \"Occur Month\",\n",
    "    \"Occur Day\",\n",
    "    \"Occur DayofWeek\",\n",
    "    \"UCR Literal\"]]\n",
    "#df.dropna(subset=['Location Type', 'Occur Time'])\n",
    "df.dropna(subset=['Beat'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer \n",
    "y = df[\"UCR Literal\"]\n",
    "X = df.drop(columns=[\"UCR Literal\"])\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder() \n",
    "X['Neighborhood']= le.fit_transform(X['Neighborhood']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61961, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n",
    "\n",
    "Use `UCR Literal` for the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For example, if variable y is a binary categorical variable with values 0 and 1 and there are 25% of zeros and 75% of ones, stratify=y will make sure that your random split has 25% of 0's and 75% of 1's.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41513, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beat</th>\n",
       "      <th>Occur Time</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Location Type</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Occur Year</th>\n",
       "      <th>Occur Month</th>\n",
       "      <th>Occur Day</th>\n",
       "      <th>Occur DayofWeek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36637</th>\n",
       "      <td>604.0</td>\n",
       "      <td>1630</td>\n",
       "      <td>4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>33.76142</td>\n",
       "      <td>-84.36492</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52369</th>\n",
       "      <td>505.0</td>\n",
       "      <td>1230</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>33.77448</td>\n",
       "      <td>-84.38263</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9562</th>\n",
       "      <td>505.0</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>33.77454</td>\n",
       "      <td>-84.37885</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21715</th>\n",
       "      <td>511.0</td>\n",
       "      <td>930</td>\n",
       "      <td>2</td>\n",
       "      <td>99.0</td>\n",
       "      <td>33.75281</td>\n",
       "      <td>-84.39197</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40637</th>\n",
       "      <td>604.0</td>\n",
       "      <td>2030</td>\n",
       "      <td>4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33.75772</td>\n",
       "      <td>-84.37067</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54343</th>\n",
       "      <td>503.0</td>\n",
       "      <td>1100</td>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33.78045</td>\n",
       "      <td>-84.38923</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38158</th>\n",
       "      <td>509.0</td>\n",
       "      <td>2250</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33.76020</td>\n",
       "      <td>-84.38554</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>208.0</td>\n",
       "      <td>1730</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>33.85166</td>\n",
       "      <td>-84.36235</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>512.0</td>\n",
       "      <td>2100</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33.75135</td>\n",
       "      <td>-84.39257</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56422</th>\n",
       "      <td>510.0</td>\n",
       "      <td>1830</td>\n",
       "      <td>2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>33.75513</td>\n",
       "      <td>-84.38216</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41513 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Beat  Occur Time  Neighborhood  Location Type  Latitude  Longitude  \\\n",
       "36637  604.0        1630             4           21.0  33.76142  -84.36492   \n",
       "52369  505.0        1230             3           13.0  33.77448  -84.38263   \n",
       "9562   505.0         200             3           13.0  33.77454  -84.37885   \n",
       "21715  511.0         930             2           99.0  33.75281  -84.39197   \n",
       "40637  604.0        2030             4           18.0  33.75772  -84.37067   \n",
       "...      ...         ...           ...            ...       ...        ...   \n",
       "54343  503.0        1100             3           18.0  33.78045  -84.38923   \n",
       "38158  509.0        2250             2           18.0  33.76020  -84.38554   \n",
       "860    208.0        1730             1            8.0  33.85166  -84.36235   \n",
       "15795  512.0        2100             2           18.0  33.75135  -84.39257   \n",
       "56422  510.0        1830             2           21.0  33.75513  -84.38216   \n",
       "\n",
       "       Occur Year  Occur Month  Occur Day  Occur DayofWeek  \n",
       "36637      2013.0         12.0       16.0              0.0  \n",
       "52369      2017.0          9.0        3.0              6.0  \n",
       "9562       2009.0          1.0        4.0              6.0  \n",
       "21715      2011.0          1.0       25.0              1.0  \n",
       "40637      2014.0         10.0       11.0              5.0  \n",
       "...           ...          ...        ...              ...  \n",
       "54343      2018.0          2.0       25.0              6.0  \n",
       "38158      2014.0          4.0       25.0              4.0  \n",
       "860        2009.0         12.0       10.0              3.0  \n",
       "15795      2009.0         12.0       16.0              2.0  \n",
       "56422      2018.0          9.0        7.0              4.0  \n",
       "\n",
       "[41513 rows x 10 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.04e+02, 1.63e+03, 4.00e+00, ..., 1.20e+01, 1.60e+01, 0.00e+00],\n",
       "       [5.05e+02, 1.23e+03, 3.00e+00, ..., 9.00e+00, 3.00e+00, 6.00e+00],\n",
       "       [5.05e+02, 2.00e+02, 3.00e+00, ..., 1.00e+00, 4.00e+00, 6.00e+00],\n",
       "       ...,\n",
       "       [2.08e+02, 1.73e+03, 1.00e+00, ..., 1.20e+01, 1.00e+01, 3.00e+00],\n",
       "       [5.12e+02, 2.10e+03, 2.00e+00, ..., 1.20e+01, 1.60e+01, 2.00e+00],\n",
       "       [5.10e+02, 1.83e+03, 2.00e+00, ..., 9.00e+00, 7.00e+00, 4.00e+00]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_scaler = MinMaxScaler().fit(X_train.to_numpy())#Compute the minimum and maximum to be used for later scaling.\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)#Scale features of X_train according to feature_range.\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "np.save('../models/DL/dl_xscaler.npy', X_scaler.scale_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using LabelEncoder and MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36637    LARCENY-FROM VEHICLE\n",
       "52369    LARCENY-FROM VEHICLE\n",
       "9562       ROBBERY-PEDESTRIAN\n",
       "21715         BURGLARY-NONRES\n",
       "40637      ROBBERY-PEDESTRIAN\n",
       "                 ...         \n",
       "54343              AUTO THEFT\n",
       "38158    LARCENY-FROM VEHICLE\n",
       "860       LARCENY-NON VEHICLE\n",
       "15795      ROBBERY-PEDESTRIAN\n",
       "56422     LARCENY-NON VEHICLE\n",
       "Name: UCR Literal, Length: 41513, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()# Should probably use OneHotEncoder instead\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/DL/scaler.sav']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(label_encoder, '../models/DL/scaler.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AGG ASSAULT', 'AUTO THEFT', 'BURGLARY-NONRES',\n",
       "       'BURGLARY-RESIDENCE', 'HOMICIDE', 'LARCENY-FROM VEHICLE',\n",
       "       'LARCENY-NON VEHICLE', 'ROBBERY-COMMERCIAL', 'ROBBERY-PEDESTRIAN',\n",
       "       'ROBBERY-RESIDENCE'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/28656736/using-scikits-labelencoder-correctly-across-multiple-programs\n",
    "#np.save('dl_classes.npy', label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "y_num_unique = y_train_categorical.shape[1]\n",
    "X_num_col = X_test_scaled.shape[1]\n",
    "model.add(Dense(units=200, activation='relu', input_dim=X_num_col))\n",
    "model.add(Dense(units=200, activation='relu', input_dim=X_num_col))\n",
    "model.add(Dense(units=200, activation='relu', input_dim=X_num_col))\n",
    "model.add(Dense(units=y_num_unique, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 200)               2200      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 84,610\n",
      "Trainable params: 84,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1298/1298 [==============================] - 1s 828us/step - loss: 1.5120 - accuracy: 0.4581\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 2/60\n",
      "1298/1298 [==============================] - 1s 889us/step - loss: 1.2195 - accuracy: 0.6039\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 3/60\n",
      "1298/1298 [==============================] - 1s 878us/step - loss: 1.1533 - accuracy: 0.6199\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 4/60\n",
      "1298/1298 [==============================] - 1s 845us/step - loss: 1.1307 - accuracy: 0.6264\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 5/60\n",
      "1298/1298 [==============================] - 1s 831us/step - loss: 1.1110 - accuracy: 0.6348\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 6/60\n",
      "1298/1298 [==============================] - 1s 875us/step - loss: 1.1038 - accuracy: 0.6345\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 7/60\n",
      "1298/1298 [==============================] - 1s 831us/step - loss: 1.0858 - accuracy: 0.6375\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 8/60\n",
      "1298/1298 [==============================] - 1s 975us/step - loss: 1.0813 - accuracy: 0.6399\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 9/60\n",
      "1298/1298 [==============================] - 1s 846us/step - loss: 1.0673 - accuracy: 0.6465\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 10/60\n",
      "1298/1298 [==============================] - 1s 863us/step - loss: 1.0654 - accuracy: 0.6486\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 11/60\n",
      "1298/1298 [==============================] - 1s 888us/step - loss: 1.0529 - accuracy: 0.6497\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 12/60\n",
      "1298/1298 [==============================] - 1s 904us/step - loss: 1.0401 - accuracy: 0.6544\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 13/60\n",
      "1298/1298 [==============================] - 1s 912us/step - loss: 1.0375 - accuracy: 0.6560\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 14/60\n",
      "1298/1298 [==============================] - 1s 829us/step - loss: 1.0314 - accuracy: 0.6578\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 15/60\n",
      "1298/1298 [==============================] - 1s 915us/step - loss: 1.0213 - accuracy: 0.6595\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 16/60\n",
      "1298/1298 [==============================] - 1s 1ms/step - loss: 1.0194 - accuracy: 0.6597\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 17/60\n",
      "1298/1298 [==============================] - 1s 1ms/step - loss: 1.0084 - accuracy: 0.6639\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 18/60\n",
      "1298/1298 [==============================] - 2s 1ms/step - loss: 1.0019 - accuracy: 0.6667\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 19/60\n",
      "1298/1298 [==============================] - 2s 1ms/step - loss: 0.9967 - accuracy: 0.6681\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 20/60\n",
      "1298/1298 [==============================] - 2s 1ms/step - loss: 0.9933 - accuracy: 0.6692\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 21/60\n",
      "1298/1298 [==============================] - 2s 1ms/step - loss: 0.9707 - accuracy: 0.6749\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 22/60\n",
      "1298/1298 [==============================] - 2s 1ms/step - loss: 0.9891 - accuracy: 0.6689\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 23/60\n",
      "1298/1298 [==============================] - 2s 1ms/step - loss: 0.9804 - accuracy: 0.6761\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 24/60\n",
      "1298/1298 [==============================] - 2s 1ms/step - loss: 0.9726 - accuracy: 0.6741\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 25/60\n",
      "1298/1298 [==============================] - 1s 1ms/step - loss: 0.9657 - accuracy: 0.6771\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 26/60\n",
      "1298/1298 [==============================] - 1s 1ms/step - loss: 0.9762 - accuracy: 0.6722\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 27/60\n",
      "1298/1298 [==============================] - 1s 1ms/step - loss: 0.9690 - accuracy: 0.6747\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 28/60\n",
      "1298/1298 [==============================] - 1s 1ms/step - loss: 0.9581 - accuracy: 0.6775\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 29/60\n",
      "1298/1298 [==============================] - 1s 931us/step - loss: 0.9497 - accuracy: 0.6797\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 30/60\n",
      "1298/1298 [==============================] - 1s 918us/step - loss: 0.9462 - accuracy: 0.6797\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 31/60\n",
      "1298/1298 [==============================] - 1s 894us/step - loss: 0.9373 - accuracy: 0.6836\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 32/60\n",
      "1298/1298 [==============================] - 1s 940us/step - loss: 0.9293 - accuracy: 0.6839\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 33/60\n",
      "1298/1298 [==============================] - 1s 906us/step - loss: 0.9400 - accuracy: 0.6834\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 34/60\n",
      "1298/1298 [==============================] - 1s 917us/step - loss: 0.9228 - accuracy: 0.6836\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 35/60\n",
      "1298/1298 [==============================] - 1s 903us/step - loss: 0.9285 - accuracy: 0.6835\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 36/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1298/1298 [==============================] - 1s 915us/step - loss: 0.9207 - accuracy: 0.6868\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 37/60\n",
      "1298/1298 [==============================] - 1s 881us/step - loss: 0.9179 - accuracy: 0.6888\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 38/60\n",
      "1298/1298 [==============================] - 1s 902us/step - loss: 0.9119 - accuracy: 0.6897\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 39/60\n",
      "1298/1298 [==============================] - 1s 893us/step - loss: 0.9081 - accuracy: 0.6897\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 40/60\n",
      "1298/1298 [==============================] - 1s 876us/step - loss: 0.9061 - accuracy: 0.6892\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 41/60\n",
      "1298/1298 [==============================] - 1s 904us/step - loss: 0.9094 - accuracy: 0.6893\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 42/60\n",
      "1298/1298 [==============================] - 1s 938us/step - loss: 0.8881 - accuracy: 0.6945\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 43/60\n",
      "1298/1298 [==============================] - 1s 945us/step - loss: 0.8903 - accuracy: 0.6937\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 44/60\n",
      "1298/1298 [==============================] - 2s 1ms/step - loss: 0.8878 - accuracy: 0.6947\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 45/60\n",
      "1298/1298 [==============================] - 1s 1ms/step - loss: 0.8788 - accuracy: 0.6971\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 46/60\n",
      "1298/1298 [==============================] - 1s 959us/step - loss: 0.8806 - accuracy: 0.6975\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 47/60\n",
      "1298/1298 [==============================] - 1s 1ms/step - loss: 0.8708 - accuracy: 0.6963\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 48/60\n",
      "1298/1298 [==============================] - 1s 990us/step - loss: 0.8673 - accuracy: 0.6971\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 49/60\n",
      "1298/1298 [==============================] - 1s 1ms/step - loss: 0.8688 - accuracy: 0.6981\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 50/60\n",
      "1298/1298 [==============================] - 1s 1ms/step - loss: 0.8571 - accuracy: 0.7003\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 51/60\n",
      "1298/1298 [==============================] - 1s 1ms/step - loss: 0.8609 - accuracy: 0.7018\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 52/60\n",
      "1298/1298 [==============================] - 1s 1ms/step - loss: 0.8427 - accuracy: 0.7082\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 53/60\n",
      "1298/1298 [==============================] - 1s 1ms/step - loss: 0.8466 - accuracy: 0.7027\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 54/60\n",
      "1298/1298 [==============================] - 1s 1ms/step - loss: 0.8252 - accuracy: 0.7129\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 55/60\n",
      "1298/1298 [==============================] - 2s 1ms/step - loss: 0.8342 - accuracy: 0.7094\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 56/60\n",
      "1298/1298 [==============================] - 2s 1ms/step - loss: 0.8236 - accuracy: 0.7100\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 57/60\n",
      "1298/1298 [==============================] - 2s 1ms/step - loss: 0.8230 - accuracy: 0.7109\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 58/60\n",
      "1298/1298 [==============================] - 2s 2ms/step - loss: 0.8126 - accuracy: 0.7155\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 59/60\n",
      "1298/1298 [==============================] - 2s 1ms/step - loss: 0.8135 - accuracy: 0.7145\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 60/60\n",
      "1298/1298 [==============================] - 2s 1ms/step - loss: 0.8048 - accuracy: 0.7192\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x149318b50>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set early stopping as callback\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=2)]\n",
    "#https://keras.rstudio.com/reference/fit.html\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    callbacks=callbacks, #List of `keras.callbacks.Callback` instances.\n",
    "    epochs=60, #Integer. Number of epochs to train the model.\n",
    "    shuffle=True,#Boolean (whether to shuffle the training data before each epoch)\n",
    "    verbose=1, #0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
    "    #view_metrics = 'auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "639/639 - 1s - loss: 1.1596 - accuracy: 0.6461\n",
      "Normal Neural Network - Loss: 1.1595799922943115, Accuracy: 0.6461267471313477\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x149170ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['BURGLARY-RESIDENCE', 'LARCENY-FROM VEHICLE', 'ROBBERY-PEDESTRIAN',\n",
       "       'LARCENY-FROM VEHICLE', 'LARCENY-FROM VEHICLE'], dtype=object)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_predictions = model.predict_classes(X_test_scaled[:5])\n",
    "prediction_labels = label_encoder.inverse_transform(encoded_predictions)\n",
    "prediction_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: ['BURGLARY-RESIDENCE' 'LARCENY-FROM VEHICLE' 'ROBBERY-PEDESTRIAN'\n",
      " 'LARCENY-FROM VEHICLE' 'LARCENY-FROM VEHICLE']\n",
      "Actual Labels: ['AUTO THEFT', 'LARCENY-FROM VEHICLE', 'ROBBERY-PEDESTRIAN', 'LARCENY-FROM VEHICLE', 'AUTO THEFT']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predicted classes: {prediction_labels}\")\n",
    "print(f\"Actual Labels: {list(y_test[:5])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/DL/deep_learning_200_200_200_10/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('../models/DL/deep_learning_200_200_200_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_scaler = MinMaxScaler()\n",
    "#X_scaled_file = np.load('../models/DL/dl_xscaler.npy',allow_pickle=True)\n",
    "my_scaler = joblib.load('../models/DL/scaler.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_scaler.inverse_transform(df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beat</th>\n",
       "      <th>Occur Time</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Location Type</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Occur Year</th>\n",
       "      <th>Occur Month</th>\n",
       "      <th>Occur Day</th>\n",
       "      <th>Occur DayofWeek</th>\n",
       "      <th>UCR Literal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206.0</td>\n",
       "      <td>57</td>\n",
       "      <td>Buckhead</td>\n",
       "      <td>99.0</td>\n",
       "      <td>33.83752</td>\n",
       "      <td>-84.37574</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ROBBERY-PEDESTRIAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Beat  Occur Time Neighborhood  Location Type  Latitude  Longitude  \\\n",
       "0  206.0          57     Buckhead           99.0  33.83752  -84.37574   \n",
       "\n",
       "   Occur Year  Occur Month  Occur Day  Occur DayofWeek         UCR Literal  \n",
       "0      2009.0          1.0        1.0              3.0  ROBBERY-PEDESTRIAN  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.18359375e+00,  2.37500000e-01,  1.00000000e+00,\n",
       "         1.01020408e+00,  2.62873322e+02, -1.57056181e+03,\n",
       "         2.01500000e+02,  9.09090909e-02,  3.33333333e-02,\n",
       "         5.00000000e-01]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>606.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.83752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-85.37574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0   606.00000\n",
       "1   570.00000\n",
       "2     4.00000\n",
       "3    99.00000\n",
       "4    35.83752\n",
       "5   -85.37574\n",
       "6  2015.00000\n",
       "7     1.00000\n",
       "8     1.00000\n",
       "9     3.00000"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([606.0, 570.0, 4.0, 99.0, 35.83752, -85.37574, 2015.0, 1.0, 1.0, 3.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-170-587d344c92b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_unscaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m606.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m570.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m99.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m35.83752\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m85.37574\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2015.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m606.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m570.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m99.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m35.83752\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m85.37574\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2015.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#X_unscaled * X_scaled_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_unknown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_unknown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                 raise ValueError(f\"y contains previously unseen labels: \"\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m_check_unknown\u001b[0;34m(values, known_values, return_mask)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;31m# check for nans in the known_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknown_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m             \u001b[0mdiff_is_nan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdiff_is_nan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "#X_unscaled = np.array([604.0, 1630.0, 0.0, 21.0, 33.76142, -84.36492, 2013.0, 12.0, 16.0, 0.0])\n",
    "X_unscaled = np.array([606.0, 570.0, 4.0, 99.0, 35.83752, -85.37574, 2015.0, 1.0, 1.0, 3.0])\n",
    "\n",
    "X_scaled = my_scaler.transform([606.0, 570.0, 4.0, 99.0, 35.83752, -85.37574, 2015.0, 1.0, 1.0, 3.0])#X_unscaled * X_scaled_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_scaled = X_scaled.reshape(1,10)# Unfortunately needs to be reshaped from (,10) to (1,10)\n",
    "reconstructed_model = keras.models.load_model(\"../models/DL/deep_learning_100_100_10\", compile=True)\n",
    "encoded_predictions = reconstructed_model.predict_classes(X_scaled)\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.classes_ = np.load('../models/DL/dl_classes.npy',allow_pickle=True)\n",
    "prediction_labels = label_encoder.inverse_transform(encoded_predictions)\n",
    "prediction_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
