{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-division",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-colorado",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://crime-data-explorer.app.cloud.gov/explorer/state/georgia/crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "renewable-privacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np, sys, time, pdb, matplotlib.pyplot as plt\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)# None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-monte",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2020 = pd.read_csv('./flask/static/data/COBRA-2020.csv')\n",
    "data_2021 = pd.read_csv('./flask/static/data/COBRA-2021.csv')\n",
    "data_2009_2019 = pd.read_csv('./flask/static/data/COBRA-2009-2019.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-christian",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2009_2019.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-overhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2020_list = data_2020.columns.values.tolist()\n",
    "data_2021_list = data_2021.columns.values.tolist()\n",
    "data_2009_2019_list = data_2009_2019.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-confirmation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(data_2020_list))\n",
    "data_2020.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-calendar",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(data_2009_2019_list))\n",
    "data_2009_2019.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-alexander",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Since the 2009-2019 dataset is the largest, everything will try and have the same columns as that dataset\n",
    "data_2020.rename(columns = {\n",
    " 'offense_id' : 'Report Number',\n",
    " 'rpt_date' : 'Report Date',\n",
    " 'occur_date' : 'Occur Date',\n",
    " 'occur_time' : 'Occur Time',\n",
    " 'poss_date' : 'Possible Date',\n",
    " 'poss_time' : 'Possible Time',\n",
    " 'beat' : 'Beat',\n",
    " 'apt_office_prefix' : 'Apartment Office Prefix',\n",
    " 'apt_office_num' : 'Apartment Number',\n",
    " 'location' : 'Location',\n",
    " #'MinOfucr' : ,\n",
    " #'dispo_code' : ,\n",
    " 'Shift' : 'Shift Occurence',\n",
    " 'loc_type' : 'Location Type',\n",
    " 'UC2_Literal': 'UCR Literal',\n",
    " 'ibr_code' : 'IBR Code',\n",
    " 'neighborhood' : 'Neighborhood',\n",
    " 'npu' : 'NPU',\n",
    " 'long' : 'Longitude',\n",
    " 'lat' : 'Latitude'\n",
    "}, inplace = True)\n",
    "#Drop columns that do not seem to show up in 2009-2019 dataset\n",
    "data_2020 = data_2020.drop(columns=['MinOfucr','dispo_code'])\n",
    "data_2020.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-portable",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = data_2009_2019.columns.values.tolist()\n",
    "list2 = data_2020.columns.values.tolist()\n",
    "\n",
    "list_difference = [item for item in list1 if item not in list2]\n",
    "print(list_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-elements",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It can be seen that the 'UCR #' shows up only in the 2009-2019 data and realistically serves no purpose because its a code only a cop would udnerstand\n",
    "#So it should be droped to simplify\n",
    "data_2009_2019 = data_2009_2019.drop(columns=['UCR #'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-ending",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-moldova",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = data_2009_2019.columns.values.tolist()\n",
    "list2 = data_2020.columns.values.tolist()\n",
    "\n",
    "list_difference = [item for item in list1 if item not in list2]\n",
    "print(list_difference)\n",
    "#There should now be no differences as at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-midwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concat the dataframes together\n",
    "data = pd.concat([data_2009_2019, data_2020])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-edward",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2009_2019['Occur Date'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Report Date'] = pd.to_datetime(data['Report Date'])\n",
    "#data['Occur Date'] = pd.to_datetime(data['Occur Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-sherman",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.astype({'Report Date':'datetime64','Occur Date':'datetime64','Possible Date':'datetime64'},errors = 'raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-tomorrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-impression",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-violence",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-richmond",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "df.to_json('data.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-animal",
   "metadata": {},
   "source": [
    "# Machine Learnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silver-booking",
   "metadata": {},
   "source": [
    "## Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-arrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\")\n",
    "# Drop the null columns where all values are null\n",
    "#df = df.dropna(axis='columns', how='all')\n",
    "# Drop the null rows\n",
    "df = df[[\"Latitude\",\"Longitude\",\"Neighborhood\"]]\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "former-concrete",
   "metadata": {},
   "source": [
    "## Create a Train Test Split\n",
    "\n",
    "Use `Neighborhood` for the y values\n",
    "This can be an idiot check to see if lat an lon can predict neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-upper",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = df[\"Neighborhood\"]\n",
    "X = df.drop(columns=[\"Neighborhood\"])\n",
    "\n",
    "#For example, if variable y is a binary categorical variable with values 0 and 1 and there are 25% of zeros and 75% of ones, stratify=y will make sure that your random split has 25% of 0's and 75% of 1's.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-hamilton",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "rental-notion",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-repository",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_scaler = MinMaxScaler().fit(X_train)#Compute the minimum and maximum to be used for later scaling.\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)#Scale features of X_train according to feature_range.\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-belly",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-subscription",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-stations",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-reach",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train_scaled, y_train)# Fit the LR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-crime",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-spanish",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Data Score: {model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {model.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-institute",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler.transform(X_train)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-cedar",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-gnome",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-briefs",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Use `GridSearchCV` to tune the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-texas",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Cfloat, default=1.0 Inverse of regularization strength; must be a positive float. Like in support vector machines, smaller values specify stronger regularization.\n",
    "# penalty{‘l1’, ‘l2’, ‘elasticnet’, ‘none’}, default=’l2’\n",
    "param_grid = {'C': [1, 3,5,7,9],\n",
    "              'penalty': [\"l1\", \"l2\", \"none\"]}\n",
    "Model = LogisticRegression(solver='liblinear')\n",
    "grid = GridSearchCV(Model, param_grid, verbose=3)\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-probe",
   "metadata": {},
   "outputs": [],
   "source": [
    "idk = grid.fit(X_train_scaled, y_train)\n",
    "idk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-chemistry",
   "metadata": {},
   "source": [
    "# Need to Decrease Sample Size\n",
    "\n",
    "It has become apparent that there is too mach data and our relatively weak computers are not up to the challenge give the time.\n",
    "\n",
    "It was decided to just look at 5 major \"Neighborhood\" of interest:\n",
    "\n",
    "buckhead, midtown, brookhaven, downtown, old fourth ward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-johnston",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\")\n",
    "# Drop the null columns where all values are null\n",
    "#df = df.dropna(axis='columns', how='all')\n",
    "# Drop the null rows\n",
    "#df_reduced = df[[\"Latitude\",\"Longitude\",\"Neighborhood\"]]\n",
    "#df_reduced = df_reduced.dropna()\n",
    "df_reduced = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-conservative",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced[\"Neighborhood\"].unique();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-level",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used to show all rows for error checking\n",
    "#pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-result",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_buckhead = df_reduced[(df_reduced[\"Neighborhood\"] == \"Buckhead Forest\") |(df_reduced[\"Neighborhood\"] == \"Buckhead Village\")\n",
    "           |(df_reduced[\"Neighborhood\"] == \"North Buckhead\") |(df_reduced[\"Neighborhood\"] == \"Buckhead Heights\")\n",
    "          ]\n",
    "df_buckhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-deficit",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_buckhead['Neighborhood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-bruce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_buckhead = df_buckhead.assign(Neighborhood = 'Buckhead' )\n",
    "df_buckhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-anatomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_other_hoods  = df_reduced[(df_reduced[\"Neighborhood\"] == \"Midtown\") | (df_reduced[\"Neighborhood\"] == \"Brookhaven\")\n",
    "          |(df_reduced[\"Neighborhood\"] == \"Downtown\") | (df_reduced[\"Neighborhood\"] == \"Old Fourth Ward\")]\n",
    "df_other_hoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-shirt",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_5hoods = pd.concat([df_buckhead,df_other_hoods], ignore_index=True, sort=False)\n",
    "df_5hoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-craps",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5hoods = df_5hoods.drop(columns=['Unnamed: 0'])\n",
    "df_5hoods.to_csv('data_5hoods.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developed-minority",
   "metadata": {},
   "source": [
    "# Machine Learnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "municipal-innocent",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3155: DtypeWarning: Columns (7,8,10,11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data_5hoods.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "north-offense",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Report Number</th>\n",
       "      <th>Beat</th>\n",
       "      <th>UCR Literal</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90010745</td>\n",
       "      <td>208.0</td>\n",
       "      <td>LARCENY-FROM VEHICLE</td>\n",
       "      <td>Buckhead</td>\n",
       "      <td>33.85115</td>\n",
       "      <td>-84.37944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Report Number   Beat           UCR Literal Neighborhood  Latitude  \\\n",
       "0       90010745  208.0  LARCENY-FROM VEHICLE     Buckhead  33.85115   \n",
       "\n",
       "   Longitude  \n",
       "0  -84.37944  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['Apartment Office Prefix',\n",
    "                      'Report Date',\n",
    "                      'Occur Date',\n",
    "                      'Occur Time',\n",
    "                      'Possible Time',\n",
    "                      'Apartment Number',\n",
    "                      'Location',\n",
    "                      'Shift Occurence',\n",
    "                      'NPU',\n",
    "                      'Possible Date',\n",
    "                      'IBR Code',\n",
    "                      'Location Type',\n",
    "                     ])\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "posted-mentor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report Number      int64\n",
      "Beat             float64\n",
      "UCR Literal       object\n",
      "Neighborhood      object\n",
      "Latitude         float64\n",
      "Longitude        float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Report Number</th>\n",
       "      <th>Beat</th>\n",
       "      <th>UCR Literal</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90010745</td>\n",
       "      <td>208.0</td>\n",
       "      <td>LARCENY-FROM VEHICLE</td>\n",
       "      <td>Buckhead</td>\n",
       "      <td>33.85115</td>\n",
       "      <td>-84.37944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Report Number   Beat           UCR Literal Neighborhood  Latitude  \\\n",
       "0       90010745  208.0  LARCENY-FROM VEHICLE     Buckhead  33.85115   \n",
       "\n",
       "   Longitude  \n",
       "0  -84.37944  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 1000)# None\n",
    "df = df.dropna()\n",
    "df[pd.to_numeric(df['Beat'], errors='coerce').notnull()]\n",
    "#df[pd.to_numeric(df['Location Type'], errors='coerce').notnull()]\n",
    "print(df.dtypes)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "engaging-weight",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer \n",
    "y = df[\"UCR Literal\"]\n",
    "X = df.drop(columns=[\"UCR Literal\"])\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder() \n",
    "X['Neighborhood']= le.fit_transform(X['Neighborhood']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "worth-confusion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Report Number</th>\n",
       "      <th>Beat</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90010745</td>\n",
       "      <td>208.0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.851150</td>\n",
       "      <td>-84.379440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90010159</td>\n",
       "      <td>206.0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.837520</td>\n",
       "      <td>-84.375740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90021591</td>\n",
       "      <td>208.0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.848830</td>\n",
       "      <td>-84.381740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90020096</td>\n",
       "      <td>208.0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.847090</td>\n",
       "      <td>-84.372950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90020730</td>\n",
       "      <td>208.0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.847120</td>\n",
       "      <td>-84.373850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65538</th>\n",
       "      <td>202741548</td>\n",
       "      <td>502.0</td>\n",
       "      <td>3</td>\n",
       "      <td>33.783060</td>\n",
       "      <td>-84.379421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65539</th>\n",
       "      <td>202740394</td>\n",
       "      <td>508.0</td>\n",
       "      <td>2</td>\n",
       "      <td>33.763927</td>\n",
       "      <td>-84.396356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65540</th>\n",
       "      <td>202740612</td>\n",
       "      <td>603.0</td>\n",
       "      <td>4</td>\n",
       "      <td>33.768814</td>\n",
       "      <td>-84.366527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65541</th>\n",
       "      <td>202740728</td>\n",
       "      <td>503.0</td>\n",
       "      <td>3</td>\n",
       "      <td>33.785508</td>\n",
       "      <td>-84.383434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65542</th>\n",
       "      <td>202741780</td>\n",
       "      <td>508.0</td>\n",
       "      <td>2</td>\n",
       "      <td>33.762930</td>\n",
       "      <td>-84.388290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65537 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Report Number   Beat  Neighborhood   Latitude  Longitude\n",
       "0           90010745  208.0             1  33.851150 -84.379440\n",
       "1           90010159  206.0             1  33.837520 -84.375740\n",
       "2           90021591  208.0             1  33.848830 -84.381740\n",
       "3           90020096  208.0             1  33.847090 -84.372950\n",
       "4           90020730  208.0             1  33.847120 -84.373850\n",
       "...              ...    ...           ...        ...        ...\n",
       "65538      202741548  502.0             3  33.783060 -84.379421\n",
       "65539      202740394  508.0             2  33.763927 -84.396356\n",
       "65540      202740612  603.0             4  33.768814 -84.366527\n",
       "65541      202740728  503.0             3  33.785508 -84.383434\n",
       "65542      202741780  508.0             2  33.762930 -84.388290\n",
       "\n",
       "[65537 rows x 5 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "alien-orleans",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc = OneHotEncoder(handle_unknown='ignore')\n",
    "# enc.fit(X)\n",
    "#For example, if variable y is a binary categorical variable with values 0 and 1 and there are 25% of zeros and 75% of ones, stratify=y will make sure that your random split has 25% of 0's and 75% of 1's.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-welsh",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "southern-survey",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_scaler = MinMaxScaler().fit(X_train)#Compute the minimum and maximum to be used for later scaling.\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)#Scale features of X_train according to feature_range.\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "chicken-london",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(solver='liblinear'),\n",
       "             param_grid={'C': [6, 7, 11], 'penalty': ['l1', 'l2', 'none']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Cfloat, default=1.0 Inverse of regularization strength; must be a positive float. Like in support vector machines, smaller values specify stronger regularization.\n",
    "# penalty{‘l1’, ‘l2’, ‘elasticnet’, ‘none’}, default=’l2’\n",
    "param_grid = {'C': [6,7,11],\n",
    "              'penalty': [\"l1\", \"l2\", \"none\"]}\n",
    "Model = LogisticRegression(solver='liblinear')\n",
    "grid = GridSearchCV(Model, param_grid, verbose=3)\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "final-density",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5] END ................................C=6, penalty=l1; total time=  12.0s\n",
      "[CV 2/5] END ................................C=6, penalty=l1; total time=  11.3s\n",
      "[CV 3/5] END ................................C=6, penalty=l1; total time=  11.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ................................C=6, penalty=l1; total time=  11.0s\n",
      "[CV 5/5] END ................................C=6, penalty=l1; total time=  11.3s\n",
      "[CV 1/5] END ................................C=6, penalty=l2; total time=   0.5s\n",
      "[CV 2/5] END ................................C=6, penalty=l2; total time=   0.5s\n",
      "[CV 3/5] END ................................C=6, penalty=l2; total time=   0.4s\n",
      "[CV 4/5] END ................................C=6, penalty=l2; total time=   0.4s\n",
      "[CV 5/5] END ................................C=6, penalty=l2; total time=   0.4s\n",
      "[CV 1/5] END ..............................C=6, penalty=none; total time=   0.0s\n",
      "[CV 2/5] END ..............................C=6, penalty=none; total time=   0.0s\n",
      "[CV 3/5] END ..............................C=6, penalty=none; total time=   0.0s\n",
      "[CV 4/5] END ..............................C=6, penalty=none; total time=   0.0s\n",
      "[CV 5/5] END ..............................C=6, penalty=none; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ................................C=7, penalty=l1; total time=  12.6s\n",
      "[CV 2/5] END ................................C=7, penalty=l1; total time=  13.0s\n",
      "[CV 3/5] END ................................C=7, penalty=l1; total time=  12.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ................................C=7, penalty=l1; total time=  13.1s\n",
      "[CV 5/5] END ................................C=7, penalty=l1; total time=  12.2s\n",
      "[CV 1/5] END ................................C=7, penalty=l2; total time=   0.5s\n",
      "[CV 2/5] END ................................C=7, penalty=l2; total time=   0.5s\n",
      "[CV 3/5] END ................................C=7, penalty=l2; total time=   0.4s\n",
      "[CV 4/5] END ................................C=7, penalty=l2; total time=   0.5s\n",
      "[CV 5/5] END ................................C=7, penalty=l2; total time=   0.5s\n",
      "[CV 1/5] END ..............................C=7, penalty=none; total time=   0.0s\n",
      "[CV 2/5] END ..............................C=7, penalty=none; total time=   0.0s\n",
      "[CV 3/5] END ..............................C=7, penalty=none; total time=   0.0s\n",
      "[CV 4/5] END ..............................C=7, penalty=none; total time=   0.0s\n",
      "[CV 5/5] END ..............................C=7, penalty=none; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...............................C=11, penalty=l1; total time=  13.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ...............................C=11, penalty=l1; total time=  14.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ...............................C=11, penalty=l1; total time=  15.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ...............................C=11, penalty=l1; total time=  13.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ...............................C=11, penalty=l1; total time=  14.3s\n",
      "[CV 1/5] END ...............................C=11, penalty=l2; total time=   0.5s\n",
      "[CV 2/5] END ...............................C=11, penalty=l2; total time=   0.5s\n",
      "[CV 3/5] END ...............................C=11, penalty=l2; total time=   0.5s\n",
      "[CV 4/5] END ...............................C=11, penalty=l2; total time=   0.5s\n",
      "[CV 5/5] END ...............................C=11, penalty=l2; total time=   0.5s\n",
      "[CV 1/5] END .............................C=11, penalty=none; total time=   0.0s\n",
      "[CV 2/5] END .............................C=11, penalty=none; total time=   0.0s\n",
      "[CV 3/5] END .............................C=11, penalty=none; total time=   0.0s\n",
      "[CV 4/5] END .............................C=11, penalty=none; total time=   0.0s\n",
      "[CV 5/5] END .............................C=11, penalty=none; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.45191193 0.45191193        nan 0.45191193 0.45191193        nan\n",
      " 0.45191193 0.45191193        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(solver='liblinear'),\n",
       "             param_grid={'C': [6, 7, 11], 'penalty': ['l1', 'l2', 'none']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "mathematical-liver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 6, 'penalty': 'l1'}\n",
      "0.45191193144366615\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-advisory",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "found-pantyhose",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-console",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save fitted model to file\n",
    "# In the specific case of scikit-learn, it may be better to use joblib’s replacement of\n",
    "# pickle (dump & load), which is more efficient on objects that carry large numpy arrays\n",
    "# internally as is often the case for fitted scikit-learn estimators, but can only pickle\n",
    "# to the disk and not to a string:\n",
    "\n",
    "import joblib\n",
    "filename = 'five_hoods_LR.sav'\n",
    "joblib.dump(grid, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-champion",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-compact",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = joblib.load(\"five_hoods_LR.sav\")\n",
    "Model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-cocktail",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
